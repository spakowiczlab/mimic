---
title: "16S ASV Generation"
output: html_document
date: "2023-06-20"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dada2)
library(tidyverse) 
library(magrittr)
library(phyloseq)
library(ggplot2)
library(fs)
library(here)
library(tools)

"config-mimic.R" %>%
    here() %>%
    source()

```

## Set up Paths and Check Data

```{r}
if (dir_exists(dada_out_dir)) {
  dir_delete(dada_out_dir)
}
dir_create(dada_out_dir)

dada_out_dir

list.files(demux_dir)
```

## Filter and Trim

```{r}

# Forward FASTQs
fnFs <- demux_dir %>%
  list.files(pattern="R1.fastq.gz",
             full.names=TRUE) %>%
  sort

fnFs <- fnFs[- 518] # Remove the unmatched fastq

print(fnFs)

# Reverse FASTQs
fnRs <- demux_dir %>%
  list.files(pattern="R2.fastq.gz",
             full.names=TRUE) %>%
  sort

fnRs <- fnRs[- 518] # Remove the unmatched fastq

print(fnRs)

```

## List of Sample Names

```{r}

forward_fastq_suffix = ".R1.fastq.gz"

sample_names <- fnFs %>% 
  basename %>%
  str_remove(forward_fastq_suffix) 

print(sample_names)

reverse_fastq_suffix = ".R2.fastq.gz"

fnRs %>% 
    basename %>%
    str_remove(reverse_fastq_suffix) ->
    rev_sample_names

identical(sample_names,rev_sample_names)

```

## Examine quality profiles of forward and reverse reads

```{r}

plotQualityProfile(fnFs, aggregate = T) 

```


```{r}

plotQualityProfile(fnRs, aggregate = T)

```

# Trim left = 5 and trunclen(230,227)

Filtering and Trimming

```{r}

filt_path <- file.path(dada_out_dir, "filtered") # Place filtered files in filtered/ subdirectory
filtFs <- file.path(filt_path, paste0(sample_names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample_names, "_R_filt.fastq.gz"))


```

```{r}

filt_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, trimLeft=5, truncLen=c(230,227),
              maxN=0, maxEE=c(2,4), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=num_cpus)

```

```{r}
filtoutput <- filt_out %>%
  data.frame()%>%
  arrange(reads.out) 

```

## Learn the Error Rates

```{r}
filtFs %>%
  file_exists %>%
  all

```

```{r}

errF <- learnErrors(filtFs, multithread=num_cpus) 

```

```{r}
errR <- learnErrors(filtRs, multithread=num_cpus)

```


```{r}
plotErrors(errF, nominalQ=TRUE)
```

## Dereplication 

```{r}

filtFs %>% 
  basename %>%
  str_replace("_F_filt.fastq.gz","") ->
  sample_names

```

```{r}

derepFs <- derepFastq(filtFs, verbose=TRUE)

```


```{r}

derepRs <- derepFastq(filtRs, verbose=TRUE)

```

```{r}

# Name the derep-class objects by the sample names
names(derepFs) <- sample_names
names(derepRs) <- sample_names

```


## Sample Inference

```{r}

dadaFs <- dada(derepFs, err=errF, multithread=num_cpus)

```

```{r}

dadaRs <- dada(derepRs, err=errR, multithread=num_cpus)

```

## Merge Paired Reads

```{r}

mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)


```

## Construct Sequence Table

```{r}

seqtab <- makeSequenceTable(mergers)
dim(seqtab)

table(nchar(getSequences(seqtab)))


```

## Remove Chimeras

```{r}

seqtab_nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=num_cpus, verbose=TRUE)

dim(seqtab_nochim)

sum(seqtab_nochim)/sum(seqtab)


```

## Collect reads per sample remaining after each step

```{r}

getN <- function(x) sum(getUniques(x))
filt_out %>%
  as_tibble(rownames = "filename") %>%
  mutate(sample=str_replace(filename, forward_fastq_suffix,"")) %>%
  select(sample, input=reads.in, filtered=reads.out) ->
  track

sapply(dadaFs, getN) %>%
  enframe(name="sample", value="denoised") ->
  denoised
track %<>% full_join(denoised, by=c("sample"))

sapply(mergers, getN) %>%
  enframe(name="sample", value="merged") ->
  merged
track %<>% full_join(merged, by=c("sample"))

rowSums(seqtab) %>%
  enframe(name="sample", value="tabled") ->
  tabled
track %<>% full_join(tabled, by=c("sample"))

rowSums(seqtab_nochim) %>%
  enframe(name="sample", value="nonchim") ->
  nonchim
track %<>% full_join(nonchim, by=c("sample"))

track

```

## Plot reads counts through pipeline

```{r}

track %>%
    gather(key="stage", value="counts", -c("sample")) %>%
    replace_na(list(counts = 0)) %>%
    mutate(stage=factor(stage, levels = c('input','filtered','denoised','merged','tabled','nonchim'))) %>%
    ggplot(mapping=aes(x=stage, y=counts, by=sample, group = sample)) +
    geom_line(alpha=0.5) +
        theme_classic()

```

## Assign Taxanomy

```{r}

taxa <- assignTaxonomy(seqtab_nochim, silva_ref, multithread=num_cpus)



```

```{r}

taxa_print <- taxa # Removing sequence rownames for display only
rownames(taxa_print) <- NULL
head(taxa_print)


```

## Saving Files

```{r}

asv_seqtab

write_rds(seqtab_nochim, asv_seqtab)

```

```{r}

asv_taxa

write_rds(taxa, asv_taxa)
```

